{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf93279-f333-4b08-87db-44bfa13ac9cf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " 帮我实现贪吃蛇小程序\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dm client received: 当然可以以下是一个简单的贪吃蛇小程序的实现使用库来创建游戏窗口和绘制蛇的图形。\n"
     ]
    }
   ],
   "source": [
    "import grpc\n",
    "from protos.nlp.dm import dm_pb2\n",
    "from protos.nlp.dm import dm_pb2_grpc\n",
    "\n",
    "def run():\n",
    "    #本地测试\n",
    "    # channel = grpc.insecure_channel('localhost:50051')\n",
    "    #chatglm测试\n",
    "    channel = grpc.insecure_channel('172.31.208.4:5555')\n",
    "    # 全部服务\n",
    "    # channel = grpc.insecure_channel('172.31.208.4:12241')\n",
    "    # 调用 rpc 服务\n",
    "    stub = dm_pb2_grpc.DmStub(channel)\n",
    "    history = {}\n",
    "    while True:\n",
    "        text = input()\n",
    "        response = stub.GetDm(dm_pb2.DmRequest(text=text, history=history,session_id='1', robot_id = -1))\n",
    "        print(\"Dm client received: \" + response.answer)\n",
    "        history = response.history\n",
    "        # print('history :', history.conversation, history.intent, history.slots, history.entities, history.task_id)\n",
    "if __name__ == '__main__':\n",
    "    run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5345a5a-9aa9-47c7-9382-63fd8faea88e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "请输入用户名称:  徐逸彬\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import json\n",
    "import os\n",
    "\n",
    "# os.environ[\"HTTP_PROXY\"] = \"http://127.0.0.1:7890\"\n",
    "# os.environ[\"HTTPS_PROXY\"] = \"http://127.0.0.1:7890\"\n",
    "\n",
    "# 获取 api\n",
    "def get_api_key():\n",
    "    # 可以自己根据自己实际情况实现\n",
    "    # 以我为例子，我是存在一个 openai_key 文件里，json 格式\n",
    "    '''\n",
    "    {\"api\": \"你的 api keys\"}\n",
    "    '''\n",
    "    openai_key_file = 'DM/models/openai_key.json'\n",
    "    with open(openai_key_file, 'r', encoding='utf-8') as f:\n",
    "        openai_key = json.loads(f.read())\n",
    "    return openai_key['api']\n",
    "openai.api_key = get_api_key() \n",
    "\n",
    "\n",
    "\n",
    "class ChatGPT:\n",
    "    def __init__(self, user):\n",
    "        self.user = user\n",
    "        self.messages = [{\"role\": \"system\", \"content\": \"一个有10年Python开发经验的资深算法工程师\"}]\n",
    "        self.filename=\"./user_messages.json\"\n",
    "\n",
    "    def ask_gpt(self):\n",
    "        rsp = openai.ChatCompletion.create(\n",
    "          model=\"gpt-3.5-turbo\",\n",
    "          messages=self.messages\n",
    "        )\n",
    "        return rsp.get(\"choices\")[0][\"message\"][\"content\"]\n",
    "\n",
    "\n",
    "    def writeTojson(self):\n",
    "        try:\n",
    "            # 判断文件是否存在\n",
    "            if not os.path.exists(self.filename):\n",
    "                with open(self.filename, \"w\") as f:\n",
    "                    # 创建文件\n",
    "                    pass\n",
    "            # 读取\n",
    "            with open(self.filename, 'r', encoding='utf-8') as f:\n",
    "                content = f.read()\n",
    "                msgs = json.loads(content) if len(content) > 0 else {}\n",
    "            # 追加\n",
    "            msgs.update({self.user : self.messages})\n",
    "            # 写入\n",
    "            with open(self.filename, 'w', encoding='utf-8') as f:\n",
    "                json.dump(msgs, f)\n",
    "        except Exception as e:\n",
    "            print(f\"错误代码：{e}\")\n",
    "            \n",
    "\n",
    "def main():\n",
    "    user = input(\"请输入用户名称: \")\n",
    "    chat = ChatGPT(user)\n",
    "    \n",
    "    # 循环\n",
    "    while 1:\n",
    "        # 限制对话次数\n",
    "        if len(chat.messages) >= 11:\n",
    "            print(\"******************************\")\n",
    "            print(\"*********强制重置对话**********\")\n",
    "            print(\"******************************\")\n",
    "            # 写入之前信息\n",
    "            chat.writeTojson()\n",
    "            user = input(\"请输入用户名称: \")\n",
    "            chat = ChatGPT(user)\n",
    "            \n",
    "        # 提问\n",
    "        q = input(f\"【{chat.user}】\")\n",
    "        # 逻辑判断\n",
    "        if q == \"0\":\n",
    "            print(\"*********退出程序**********\")\n",
    "            # 写入之前信息\n",
    "            chat.writeTojson()\n",
    "            break\n",
    "        elif q == \"1\":\n",
    "            print(\"**************************\")\n",
    "            print(\"*********重置对话**********\")\n",
    "            print(\"**************************\")\n",
    "            # 写入之前信息\n",
    "            chat.writeTojson()\n",
    "            user = input(\"请输入用户名称: \")\n",
    "            chat = ChatGPT(user)\n",
    "            continue\n",
    "            \n",
    "        # 提问-回答-记录\n",
    "        chat.messages.append({\"role\": \"user\", \"content\": q})\n",
    "        answer = chat.ask_gpt()\n",
    "        print(f\"【ChatGPT】{answer}\")\n",
    "        chat.messages.append({\"role\": \"assistant\", \"content\": answer})\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b5ab754-cd7f-4a4f-81c2-122c8ec97558",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xuyibin/anaconda3/envs/dm/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "#Mean Pooling - Take attention mask into account for correct averaging\n",
    "def mean_pooling(model_output, attention_mask):\n",
    "    token_embeddings = model_output[0] #First element of model_output contains all token embeddings\n",
    "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "    return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "\n",
    "\n",
    "# Sentences we want sentence embeddings for\n",
    "sentences = [\"明晚八点\",'帮我订明天晚上八点的票' ,\"机票订后天的\",'后天早上出发','今晚十点左右出发','深圳','北京','上海','深圳','成都','武汉','西安','广州','确定','取消','否','yes','no','感冒发烧','结婚度假']\n",
    "\n",
    "# Load model from HuggingFace Hub\n",
    "tokenizer = AutoTokenizer.from_pretrained('DM/models/sbert-chinese-general-v2/')\n",
    "model = AutoModel.from_pretrained('DM/models/sbert-chinese-general-v2/')\n",
    "\n",
    "# Tokenize sentences\n",
    "encoded_input = tokenizer(sentences, padding=True, truncation=True, return_tensors='pt')\n",
    "\n",
    "# Compute token embeddings\n",
    "with torch.no_grad():\n",
    "    model_output = model(**encoded_input)\n",
    "\n",
    "# Perform pooling. In this case, mean pooling.\n",
    "sentence_embeddings = mean_pooling(model_output, encoded_input['attention_mask'])\n",
    "np.save('DM/data/candidate_vectors.npy', sentence_embeddings)\n",
    "# cosine_similarities = torch.nn.functional.cosine_similarity(sentence_embeddings[0], sentence_embeddings[1], dim=0)\n",
    "# print(cosine_similarities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e05a9ddc-a2a8-4a88-ac22-a0a602b6ac89",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5036687850952148\n"
     ]
    }
   ],
   "source": [
    "vectors = np.load('DM/data/candidate_vectors.npy')\n",
    "new_text = \"明天北京下雨吗\"\n",
    "# 生成新文本向量\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('DM/models/sbert-chinese-general-v2/')\n",
    "model = AutoModel.from_pretrained('DM/models/sbert-chinese-general-v2/')\n",
    "\n",
    "# Tokenize sentences\n",
    "encoded_input = tokenizer(new_text, padding=True, truncation=True, return_tensors='pt')\n",
    "with torch.no_grad():\n",
    "    model_output = model(**encoded_input)\n",
    "\n",
    "# Perform pooling. In this case, mean pooling.\n",
    "sentence_embeddings = mean_pooling(model_output, encoded_input['attention_mask'])\n",
    "similarity_scores = torch.nn.functional.cosine_similarity(sentence_embeddings, torch.from_numpy(vectors))\n",
    "print(max(similarity_scores).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "05405b97-c6b8-4dde-a6d3-9ccd0a5cef1d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7718915343284607\n"
     ]
    }
   ],
   "source": [
    "from annoy import AnnoyIndex\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def mean_pooling(model_output, attention_mask):\n",
    "    token_embeddings = model_output[0] #First element of model_output contains all token embeddings\n",
    "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "    return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "\n",
    "\n",
    "query = '机票订后天晚上八点的'\n",
    "candidate_vectors = np.load('DM/data/candidate_vectors.npy')\n",
    "tokenizer = AutoTokenizer.from_pretrained('DM/models/sbert-chinese-general-v2-distill/')\n",
    "model = AutoModel.from_pretrained('DM/models/sbert-chinese-general-v2-distill/')\n",
    "encoded_input = tokenizer(query, padding=True, truncation=True, return_tensors='pt')\n",
    "with torch.no_grad():\n",
    "    model_output = model(**encoded_input)\n",
    "\n",
    "# Perform pooling. In this case, mean pooling.\n",
    "new_vector = mean_pooling(model_output, encoded_input['attention_mask'])\n",
    "similarity_scores = torch.nn.functional.cosine_similarity(new_vector, torch.from_numpy(vectors))\n",
    "print(max(similarity_scores).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d18274-0f73-4646-99bb-4fd20b90420e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
